
# Manual T√©cnico: API de Chatbot Laguna

## √çndice
0. [Explicaciones T√©cnicas](#explicaciones-t√©cnicas)  
1. [Introducci√≥n](#introducci√≥n)  
2. [Requisitos Previos](#requisitos-previos)  
3. [Configuraci√≥n del Entorno](#configuraci√≥n-del-entorno)  
4. [Despliegue en Hugging Face Spaces](#despliegue-en-hugging-face-spaces)  
5. [Endpoints de la API](#endpoints-de-la-api)  
6. [Gesti√≥n de Documentos](#gesti√≥n-de-documentos)  
7. [WebSockets](#websockets)  
8. [Integraci√≥n con MongoDB](#integraci√≥n-con-mongodb)  
9. [Soluci√≥n de Problemas](#soluci√≥n-de-problemas)  
10. [Ap√©ndices](#ap√©ndices)

---
## 0. Explicaciones T√©cnicas <a name="explicaciones-t√©cnicas"></a>

### 0.1 ¬øQu√© es Hugging Face?
Hugging Face es una plataforma que proporciona modelos de lenguaje preentrenados (LLMs) y herramientas para procesamiento de lenguaje natural (NLP). En este proyecto, se utiliza para acceder a modelos como Mistral-7B y generar embeddings.

### 0.2 ¬øQu√© es Langchain?
Langchain es un framework que facilita la creaci√≥n de aplicaciones basadas en modelos de lenguaje. Permite integrar diferentes componentes como modelos, bases de datos y herramientas externas en un flujo de trabajo coherente.

### 0.3 ¬øQu√© es un RAGbot?
Un RAGbot (Retrieval-Augmented Generation bot) es un chatbot que combina la generaci√≥n de lenguaje con la recuperaci√≥n de informaci√≥n. En este proyecto, el RAGbot recupera informaci√≥n relevante de los documentos cargados y la utiliza para generar respuestas m√°s precisas.

### 0.4 ¬øQu√© es Docker?
Docker es una plataforma que permite empaquetar aplicaciones y sus dependencias en contenedores. Esto facilita el despliegue y la ejecuci√≥n de aplicaciones en diferentes entornos sin problemas de compatibilidad.

### 0.5 ¬øQu√© es MongoDB?
MongoDB es una base de datos NoSQL que almacena datos en formato JSON-like. En este proyecto, se utiliza para almacenar documentos y conversaciones de manera persistente.
---

## 1. Introducci√≥n <a name="introducci√≥n"></a>
La API de Chatbot Laguna es una soluci√≥n multimodal que combina:
- Modelos LLM de Hugging Face/Mistral
- Procesamiento de PDFs con Unstructured
- RAG (Retrieval-Augmented Generation) con Langchain
- Almacenamiento vectorial con ChromaDB
- Integraci√≥n con MongoDB para persistencia

Funcionalidades clave:
- Carga y an√°lisis de documentos PDF
- Consultas en lenguaje natural con contexto multimodal
- Web scraping y generaci√≥n de reportes PDF
- Comunicaci√≥n en tiempo real v√≠a WebSockets

---

## 2. Requisitos Previos <a name="requisitos-previos"></a>

### 2.1 Cuentas Requeridas
1. **Hugging Face**  
   - Registro en [huggingface.co](https://huggingface.co)
   - Obtener API Token desde [Settings ‚Üí Access Tokens](https://huggingface.co/settings/tokens)

2. **Groq Cloud**  
   - Registro en [console.groq.com](https://console.groq.com)
   - Crear API Key en secci√≥n "API Keys"

3. **MongoDB Atlas**  
   - Crear cuenta gratis en [mongodb.com](https://www.mongodb.com)
   - Crear cluster y obtener URI de conexi√≥n
4. **Langchain**
    - Crear una cuenta gratis en [langchain.com](https://smith.langchain.com/)
    - Crear una API Key en la seccion de "API Keys"

### 2.2 Herramientas
- Python 3.9+
- Git
- Docker (opcional para despliegue)
- Postman/Insomnia para pruebas

---

## 3. Configuraci√≥n del Entorno <a name="configuraci√≥n-del-entorno"></a>

### 3.1 Instalaci√≥n
```bash
# Clonar repositorio
git clone https://github.com/TecLaguna/ChatBotLaguna.git
cd chatbot-laguna

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate  # Windows

# Instalar dependencias
pip install -r requirements.txt
```

### 3.2 Configurar Variables de Entorno
Crear archivo `.env` en la ra√≠z del proyecto:
```ini
GROQ_API_KEY=tu_api_key_groq
MONGODB_URI=mongodb+srv://usuario:contrase√±a@cluster.mongodb.net/db
HUGGINGFACEHUB_API_TOKEN=tu_token_hf
LANGCHAIN_API_KEY=tu_key_langchain
```

### 3.3 Estructura de Carpetas
```
chatbot-laguna/
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ documents/  # PDFs cargados
‚îú‚îÄ‚îÄ _temp/      # Datos temporales
‚îî‚îÄ‚îÄ images/     # Im√°genes descargadas
```

---

## 4. Despliegue en Hugging Face Spaces <a name="despliegue-en-hugging-face-spaces"></a>

### 4.1 Configurar Dockerfile
```dockerfile
FROM python:3.10

# Define variables de entorno
ENV HOST=0.0.0.0
ENV LISTEN_PORT=7860

# Expone el puerto 7860 para que se pueda acceder desde fuera del contenedor
EXPOSE 7860

# Actualiza el sistema e instala dependencias necesarias (ejecutado como root)
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    poppler-utils \
    tesseract-ocr \
    gcc \
    g++ \
    make \
    wget \
    libsqlite3-dev \
    sqlite3 \
    zlib1g-dev \
    libssl-dev \
    libffi-dev \
    libncurses5-dev \
    libncursesw5-dev \
    libreadline-dev \
    libbz2-dev \
    liblzma-dev \
    && rm -rf /var/lib/apt/lists/*

# Descargar y compilar una versi√≥n compatible de SQLite
RUN wget https://www.sqlite.org/2024/sqlite-autoconf-3450100.tar.gz && \
    tar -xzf sqlite-autoconf-3450100.tar.gz && \
    cd sqlite-autoconf-3450100 && \
    ./configure --prefix=/usr && \
    make && \
    make install && \
    cd .. && \
    rm -rf sqlite-autoconf-3450100 sqlite-autoconf-3450100.tar.gz

# Verificar la versi√≥n de SQLite instalada
RUN sqlite3 --version

# Recompilar Python para que use la nueva versi√≥n de SQLite
RUN wget https://www.python.org/ftp/python/3.10.13/Python-3.10.13.tgz && \
    tar -xzf Python-3.10.13.tgz && \
    cd Python-3.10.13 && \
    ./configure --enable-optimizations --with-ensurepip=install && \
    make && \
    make install && \
    cd .. && \
    rm -rf Python-3.10.13 Python-3.10.13.tgz

# Verificar que Python usa la nueva versi√≥n de SQLite
RUN python3 -c "import sqlite3; print('SQLite Version:', sqlite3.sqlite_version)"

# üîπ Ahora creamos el usuario y cambiamos permisos
RUN useradd -m -u 1000 user
USER user
ENV HOME=/home/user \
    PATH=/home/user/.local/bin:$PATH
WORKDIR $HOME/app

# Copia el archivo de dependencias y las instala sin cach√© para optimizar el tama√±o del contenedor
COPY --chown=user requirements.txt .
RUN pip install --no-cache-dir --upgrade -r requirements.txt

# Copia el c√≥digo fuente de la aplicaci√≥n al contenedor
COPY --chown=user . .

# Comando por defecto al iniciar el contenedor
CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "7860"]
```

### 4.2 Pasos de Despliegue
1. Crear nuevo Space en HF
2. Seleccionar "Docker" como backend
3. Subir archivos v√≠a Git:
```bash
git init
git add .
git commit -m "Initial commit"
git push huggingface main
```

### 4.3 Configurar Secrets
En la configuraci√≥n del Space, agregar las variables de entorno como "Secrets".

---

## 5. Endpoints de la API <a name="endpoints-de-la-api"></a>

### 5.1 Carga de Documentos PDF
**Endpoint**: `POST /embed`  
**Body**: Form-data con archivo PDF

Ejemplo cURL:
```bash
curl -X POST -F "file=@documento.pdf" http://localhost:8000/embed
```

Respuesta exitosa:
```json
{
  "message": "PDF procesado y datos incrustados correctamente"
}
```

### 5.2 Consultas al Chatbot
**Endpoint**: `POST /query`  
**Body**:
```json
{
  "question": "¬øQu√© requisitos hay para la beca?",
  "conversation_name": "Becas"
}
```

Ejemplo de respuesta:
```json
{
  "response": "Los requisitos principales son... intent:university_related"
}
```

### 5.3 Web Scraping y Generaci√≥n de PDF
**Endpoint**: `POST /scrape_and_embed`  
**Body**:
```json
{
  "links": ["https://universidad.edu.mx/becas"]
}
```

---

## 6. Gesti√≥n de Documentos <a name="gesti√≥n-de-documentos"></a>

### 6.1 Listar Documentos
```bash
GET /get_documents
```

### 6.2 Eliminar Documento
```bash
POST /delete_document
Body: { "id": "document_id" }
```

---

## 7. WebSockets <a name="websockets"></a>
Conexi√≥n para chat en tiempo real:
```javascript
const socket = new WebSocket('ws://localhost:8000/ws');

socket.onmessage = (event) => {
  console.log('Mensaje recibido:', event.data);
};
```

---

## 8. Integraci√≥n con MongoDB <a name="integraci√≥n-con-mongodb"></a>

### 8.1 Estructura de Datos
**Documentos**:
```json
{
  "_id": ObjectId,
  "file_path": "documents/informe.pdf",
  "doc_ids": ["uuid1", "uuid2"],
  "texts": ["texto extra√≠do..."],
  "tables": [["datos tabla"]],
  "upload_date": ISODate()
}
```

**Conversaciones**:
```json
{
  "conversation_name": "Becas",
  "question": "¬øQu√© requisitos hay?",
  "response": "Los requisitos son...",
  "timestamp": ISODate(),
  "status": "Success"
}
```

---

## 9. Soluci√≥n de Problemas <a name="soluci√≥n-de-problemas"></a>

### Error: `SSL_CERT_FILE` no encontrado
**Soluci√≥n**:
```python
import certifi
os.environ['SSL_CERT_FILE'] = certifi.where()
```

### Error: Timeout en Hugging Face
**Posibles causas**:
1. L√≠mite de tokens excedido
2. Modelo no disponible
3. Problemas de red

**Soluci√≥n**:
- Verificar estado del modelo en [HF Status](https://status.huggingface.co)
- Reducir `max_length` en la configuraci√≥n

---

## 10. Ap√©ndices <a name="ap√©ndices"></a>

### A. Diagrama de Arquitectura
```
[Usuario] ‚Üí [FastAPI] ‚Üî [ChromaDB]
                   ‚Ü≥ [Hugging Face]
                   ‚Ü≥ [MongoDB]
                   ‚Ü≥ [WebSocket]
```

### B. Dependencias Clave
```python
langchain==0.1.0
fastapi==0.109.0
pymongo==4.6.1
unstructured==0.12.2
huggingface_hub==0.20.2
```

### C. Informaci√≥n del Contribuidor

**Contribuidor Principal**:  
**Carlos Roberto Rocha Trejo**  
- **GitHub**: [@RobertoRochaT](https://github.com/RobertoRochaT)  
- **LinkedIn**: [Carlos Roberto Rocha Trejo](https://linkedin.com/in/carlosr-rocha)  
- **Rol**: Desarrollador.
- **Contribuciones**:
  - Integraci√≥n de modelos de lenguaje avanzados (LLMs) y sistemas de recuperaci√≥n de informaci√≥n (RAG).  
  - Desarrollo de la API RESTful y WebSockets para comunicaci√≥n en tiempo real.  
  - Implementaci√≥n de la base de datos vectorial (ChromaDB) y persistencia en MongoDB.  
  - Optimizaci√≥n del contenedor Docker para despliegue en Hugging Face Spaces.  

---

**Agradecimientos Especiales**:  
Agradecemos a todos los colaboradores y a la comunidad de c√≥digo abierto por su invaluable apoyo en el desarrollo de este proyecto. Su dedicaci√≥n y expertise han sido fundamentales para el √©xito de esta iniciativa.  

---

Este manual y el proyecto son mantenidos activamente por el equipo de desarrollo. ¬°Gracias por tu inter√©s en Chatbot Laguna! üöÄ
